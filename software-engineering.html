<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Software-Engineering - Portfolio Page</title>
    <meta property="og:title" content="Software-Engineering - Portfolio Page" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta charset="utf-8" />
    <meta property="twitter:card" content="summary_large_image" />

    <style data-tag="reset-style-sheet">
      html {  line-height: 1.15;}body {  margin: 0;}* {  box-sizing: border-box;  border-width: 0;  border-style: solid;}p,li,ul,pre,div,h1,h2,h3,h4,h5,h6,figure,blockquote,figcaption {  margin: 0;  padding: 0;}button {  background-color: transparent;}button,input,optgroup,select,textarea {  font-family: inherit;  font-size: 100%;  line-height: 1.15;  margin: 0;}button,select {  text-transform: none;}button,[type="button"],[type="reset"],[type="submit"] {  -webkit-appearance: button;}button::-moz-focus-inner,[type="button"]::-moz-focus-inner,[type="reset"]::-moz-focus-inner,[type="submit"]::-moz-focus-inner {  border-style: none;  padding: 0;}button:-moz-focus,[type="button"]:-moz-focus,[type="reset"]:-moz-focus,[type="submit"]:-moz-focus {  outline: 1px dotted ButtonText;}a {  color: inherit;  text-decoration: inherit;}input {  padding: 2px 4px;}img {  display: block;}html { scroll-behavior: smooth  }
    </style>
    <style data-tag="default-style-sheet">
      html {
        font-family: Arial;
        font-size: 16px;
      }

      body {
        font-weight: 400;
        font-style:normal;
        text-decoration: none;
        text-transform: none;
        letter-spacing: normal;
        line-height: 1.55;
        color: var(--dl-color-gray-black);
        background-color: var(--dl-color-gray-white);

      }
    </style>
    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300;0,400;0,600;0,700;0,800;1,300;1,400;1,600;1,700;1,800&amp;display=swap"
      data-tag="font"
    />
    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/css2?family=Playfair+Display:ital,wght@0,400;0,500;0,600;0,700;0,800;0,900;1,400;1,500;1,600;1,700;1,800;1,900&amp;display=swap"
      data-tag="font"
    />
    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/css2?family=Overpass:ital,wght@0,100;0,200;0,300;0,400;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,600;1,700;1,800;1,900&amp;display=swap"
      data-tag="font"
    />
    <link rel="stylesheet" href="./style.css" />
  </head>
  <body>
    <div>
      <link href="./software-engineering.css" rel="stylesheet" />

      <div class="software-engineering-container">
        <div class="software-engineering-container01">
          <div class="software-engineering-container02">
            <h1 class="software-engineering-text">Prathik Srinivasan</h1>
            <span>
              <span>Software Engineer</span>
              <br />
            </span>
          </div>
        </div>
        <div class="software-engineering-container03">
          <img
            alt="image"
            src="public/pfp-300h.png"
            class="software-engineering-image"
          />
          <span class="software-engineering-text04">
            <span>
              Hi! I'm Prathik, a software engineer with a passion for machine
              learning and computer vision.
            </span>
            <br />
            <br />
            <span>
              I'm currently attending the University of Illinois at
              Urbana-Champaign as a graduate student for Computer Science.
              Previously, I obtained my bachelor's degree in Electrical and
              Computer Engineering from the University of Texas at Austin.
            </span>
            <br />
          </span>
        </div>
        <h1>Projects</h1>
        <div class="software-engineering-container04">
          <div class="software-engineering-blog">
            <div class="software-engineering-container05">
              <div class="tbdne-blog-post-card tbdne-root-class-name1">
                <div class="tbdne-container">
                  <span class="tbdne-text"><span>'TBDNE' Web Game</span></span>
                  <span class="tbdne-text1">
                    <span>Unity, Google Firebase, C#, Javascript</span>
                  </span>
                  <span class="tbdne-text2">
                    <span>
                      A progressive web-based puzzle game where users attempt to
                      distinguish between real and AI-generated images. I was
                      responsible for front-end design as well as creating and
                      integrating a Google Firebase database to collect and
                      analyze game metrics to improve the puzzle generation
                      model.
                    </span>
                  </span>
                  <div class="tbdne-container1">
                    <a
                      href="https://www.tbdne.com/"
                      target="_blank"
                      rel="noreferrer noopener"
                      class="tbdne-link"
                    >
                      <img
                        alt="image"
                        src="public/pngwing.com%20(2)-200h.png"
                        class="tbdne-image"
                      />
                    </a>
                  </div>
                </div>
              </div>
            </div>
            <div class="software-engineering-container06">
              <div
                class="posetransfer-blog-post-card posetransfer-root-class-name3"
              >
                <div class="posetransfer-container">
                  <span class="posetransfer-text">
                    <span>Generative Pose Transfer Models</span>
                  </span>
                  <span class="posetransfer-text1">
                    <span>Python, PyTorch, Stable Diffusion</span>
                  </span>
                  <span class="posetransfer-text2">
                    <span>
                      An exploration of training multiple different generative
                      image models to create sprite sheet animations using a
                      photo of a person as a source image. I tried both a GAN
                      model created in PyTorch and a stable diffusion model that
                      was fine-tuned on source images.
                    </span>
                  </span>
                  <div class="posetransfer-container1">
                    <a
                      href="https://youtu.be/KOInxNK26qc"
                      target="_blank"
                      rel="noreferrer noopener"
                      class="posetransfer-link"
                    >
                      <img
                        alt="image"
                        src="public/717426-200h.png"
                        class="posetransfer-image"
                      />
                    </a>
                    <a
                      href="https://github.com/prathiksrinivasan/PoseTransferExploration"
                      target="_blank"
                      rel="noreferrer noopener"
                      class="posetransfer-link1"
                    >
                      <img
                        alt="image"
                        src="public/25231-200h.png"
                        class="posetransfer-image1"
                      />
                    </a>
                  </div>
                </div>
              </div>
            </div>
            <div class="software-engineering-container07">
              <div
                class="imagesegmentation-blog-post-card imagesegmentation-root-class-name"
              >
                <div class="imagesegmentation-container">
                  <span class="imagesegmentation-text">
                    <span>Segmentation Model for Edge Devices</span>
                  </span>
                  <span class="imagesegmentation-text1">
                    <span>Python, PyTorch</span>
                  </span>
                  <span class="imagesegmentation-text2">
                    <span>
                      Optimization techniques including pruning and quantization
                      were applied to a ResNet image segmentation model to
                      maximize efficiency. Model maintained 85% accuracy on the
                      Cifar-10 image dataset with massive improvements in
                      prediction latency and energy consumption when deployed on
                      Raspberry Pi.
                    </span>
                  </span>
                  <div class="imagesegmentation-container1">
                    <a
                      href="https://github.com/prathiksrinivasan/ResNetOptimization"
                      target="_blank"
                      rel="noreferrer noopener"
                      class="imagesegmentation-link"
                    >
                      <img
                        alt="image"
                        src="public/25231-200h.png"
                        class="imagesegmentation-image"
                      />
                    </a>
                  </div>
                </div>
              </div>
            </div>
          </div>
          <div class="software-engineering-blog1">
            <div class="software-engineering-container08">
              <div
                class="connectivia-blog-post-card connectivia-root-class-name"
              >
                <div class="connectivia-container">
                  <span class="connectivia-text">
                    <span>Crop Prediction Model</span>
                  </span>
                  <span class="connectivia-text1">
                    <span>Python, Tensorflow, MongoDB, Docker</span>
                  </span>
                  <span class="connectivia-text2">
                    <span>
                      Trained a machine learning model to predict optimal crop
                      selections for climate using Python's Tensorflow library
                      with data stored and retrieved from a MongoDB database.
                      Virtualized machine learning model to run on Ubuntu-based
                      edge devices using Docker.
                    </span>
                  </span>
                  <div class="connectivia-container1"></div>
                </div>
              </div>
            </div>
            <div class="software-engineering-container09">
              <div
                class="workoutbuddy-blog-post-card workoutbuddy-root-class-name1"
              >
                <div class="workoutbuddy-container">
                  <span class="workoutbuddy-text">
                    <span>'Workout Buddy' Android Application</span>
                  </span>
                  <span class="workoutbuddy-text1">
                    <span>Java, Kotlin, Android Studio</span>
                  </span>
                  <span class="workoutbuddy-text2">
                    <span>
                      Used Android Studio to design and develop an Android
                      application that would track exercise metrics and
                      incentivise users with social gamification elements.
                      Created custom layout and developed front-end widgets,
                      animations, and UI elements with Java and Kotlin.
                    </span>
                  </span>
                  <div class="workoutbuddy-container1"></div>
                </div>
              </div>
            </div>
            <div class="software-engineering-container10">
              <div
                class="gesturedrawing-blog-post-card gesturedrawing-root-class-name"
              >
                <div class="gesturedrawing-container">
                  <span class="gesturedrawing-text">
                    <span>Gesture Drawing Grader</span>
                  </span>
                  <span class="gesturedrawing-text1">
                    <span>Python, OpenCV, SKLearn</span>
                  </span>
                  <span class="gesturedrawing-text2">
                    <span>
                      With a pre-trained deep learning model, we developed a
                      system that would compare the similarity between a
                      reference image and a user's drawing. 25 human body
                      landmarks were compared with the gesture drawing using a
                      cosine similarity algorithm, calculating a "grade" for the
                      pose accuracy.
                    </span>
                  </span>
                  <div class="gesturedrawing-container1">
                    <a
                      href="https://github.com/prathiksrinivasan/GestureDrawingGrader_CVs22"
                      target="_blank"
                      rel="noreferrer noopener"
                      class="gesturedrawing-link"
                    >
                      <img
                        alt="image"
                        src="public/25231-200h.png"
                        class="gesturedrawing-image"
                      />
                    </a>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <script src="https://unpkg.com/@teleporthq/teleport-custom-scripts"></script>
  </body>
</html>
